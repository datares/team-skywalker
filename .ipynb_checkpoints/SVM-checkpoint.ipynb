{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08503189-74d2-4d08-8c3c-c5dc862764ff",
   "metadata": {},
   "source": [
    "# Machine Learning Starter Code\n",
    "This notebook is a simple skeleton to give an example of how to split code and train a model. More research will be needed on the specific documentation of whatever model you are investigating. As it is this notebook will not run since df is undefined. Simply replace df with the cleaned kepler dataframe (whatever you want to call it) and replace 'label' with the column name of the label we are choosing (eg pdisposition). Hope this helps!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d123b5-88ea-4dc5-879e-4d3ab49b0985",
   "metadata": {},
   "source": [
    "## Loading Essentials and Helper Functions \n",
    "This is a lolt of imports and you may not use all of them but some of them may be useful, and looking into the documentation can help you learn (eg sklearn.metrics can help give you an idea of how to asses the usefulness of a particular model!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60d03e03-9a08-4ab9-9846-e88f7f3e8c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feel free to use these or equivalent libraries for your implementation\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # this is used for the plot the graph \n",
    "import os\n",
    "import seaborn as sns # used for plot interactive graph.\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.metrics.cluster as smc\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import itertools\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import random \n",
    "  \n",
    "random.seed(42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7adfe13-2b90-4e29-ae84-b7528e89046d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9564 entries, 0 to 9563\n",
      "Data columns (total 25 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   kepoi_name         9564 non-null   object \n",
      " 1   kepler_name        2295 non-null   object \n",
      " 2   koi_pdisposition   9564 non-null   int32  \n",
      " 3   koi_score          8054 non-null   float64\n",
      " 4   koi_fpflag_nt      9564 non-null   int64  \n",
      " 5   koi_fpflag_ss      9564 non-null   int64  \n",
      " 6   koi_fpflag_co      9564 non-null   int64  \n",
      " 7   koi_fpflag_ec      9564 non-null   int64  \n",
      " 8   koi_period         9564 non-null   float64\n",
      " 9   koi_time0bk        9564 non-null   float64\n",
      " 10  koi_impact         9201 non-null   float64\n",
      " 11  koi_duration       9564 non-null   float64\n",
      " 12  koi_depth          9201 non-null   float64\n",
      " 13  koi_prad           9201 non-null   float64\n",
      " 14  koi_teq            9201 non-null   float64\n",
      " 15  koi_insol          9243 non-null   float64\n",
      " 16  koi_model_snr      9201 non-null   float64\n",
      " 17  koi_tce_plnt_num   9218 non-null   float64\n",
      " 18  koi_tce_delivname  9218 non-null   object \n",
      " 19  koi_steff          9201 non-null   float64\n",
      " 20  koi_slogg          9201 non-null   float64\n",
      " 21  koi_srad           9201 non-null   float64\n",
      " 22  ra                 9564 non-null   float64\n",
      " 23  dec                9564 non-null   float64\n",
      " 24  koi_kepmag         9563 non-null   float64\n",
      "dtypes: float64(17), int32(1), int64(4), object(3)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "rawData = pd.read_csv(\"Kepler_Data.csv\")\n",
    "rawData = rawData.drop(\"koi_disposition\", axis = 1)\n",
    "rawData = rawData.drop([\"rowid\", \"kepid\"], axis = 1)\n",
    "dropCols = rawData.filter(regex=\"err\\d$\").columns\n",
    "rawData = rawData.drop(dropCols,axis = 1)\n",
    "# %%\n",
    "le = LabelEncoder()\n",
    "rawData['koi_pdisposition'] = le.fit_transform(rawData['koi_pdisposition'])\n",
    "rawData.info()\n",
    "numericCols = rawData.select_dtypes(np.number).columns.to_list()\n",
    "ss = StandardScaler()\n",
    "rawData[numericCols] = ss.fit_transform(rawData[numericCols])\n",
    "rawData.to_csv(\"cleanData2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30e2c7ba-cbec-4b48-af84-b0061751def0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "first argument must be an iterable of pandas objects, you passed an object of type \"DataFrame\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-5907db9c45bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"rowid\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"kepid\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mcleanData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[0mcleanData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cleanData2.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\datafest21\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIndexes\u001b[0m \u001b[0mhave\u001b[0m \u001b[0moverlapping\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m     \"\"\"\n\u001b[1;32m--> 285\u001b[1;33m     op = _Concatenator(\n\u001b[0m\u001b[0;32m    286\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\datafest21\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    318\u001b[0m     ):\n\u001b[0;32m    319\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mABCSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m             raise TypeError(\n\u001b[0m\u001b[0;32m    321\u001b[0m                 \u001b[1;34m\"first argument must be an iterable of pandas \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[1;34mf'objects, you passed an object of type \"{type(objs).__name__}\"'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: first argument must be an iterable of pandas objects, you passed an object of type \"DataFrame\""
     ]
    }
   ],
   "source": [
    "rawData = pd.read_csv(\"Kepler_Data.csv\")\n",
    "rawData = rawData.drop(\"koi_disposition\", axis = 1)\n",
    "dropCols = rawData.filter(regex=\"err\\d$\").columns\n",
    "rawData = rawData.drop(dropCols,axis = 1)\n",
    "# %%\n",
    "le = LabelEncoder()\n",
    "le.fit_transform(rawData['koi_pdisposition'], inplace=True)\n",
    "X = rawData.drop(\"koi_pdisposition\", axis = 1)\n",
    "#%%\n",
    "#%\n",
    "# drop error columns\n",
    "dropCols = rawData.filter(regex=\"err\\d$\").columns\n",
    "rawData = rawData.drop(dropCols,axis = 1)\n",
    "# \n",
    "numericCols = rawData.select_dtypes(np.number).columns.to_list()\n",
    "X = X[numericCols]\n",
    "ss = StandardScaler()\n",
    "\n",
    "# find numeric columns\n",
    "X = X.fillna(0)\n",
    "X[numericCols] = ss.fit_transform(X)\n",
    "X = X.drop([\"rowid\", \"kepid\"], axis = 1)\n",
    "\n",
    "cleanData = pd.concat(X,y);\n",
    "cleanData.to_csv(\"cleanData2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b93951-fb37-452a-913b-c86ab0eea77a",
   "metadata": {},
   "source": [
    "### Save the label column as a separate array and then drop it from the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd1dbff-6db9-4e90-912d-aed33f21b348",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"koi_pdisposition\"\n",
    "y = df[label]\n",
    "x = df.drop(label, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27ab2f1-9019-4ef1-9b7b-26be3882dc6c",
   "metadata": {},
   "source": [
    "### Split the data into train, test, target, and target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73312df0-b03f-4434-8e04-927245286179",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, target, target_test = train_test_split(x, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab1eea9-f457-43bf-8c78-4d9bd5d01556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-Nearest Neighbors algorithm, this can be replaced with whatever model you are using (eg Naive Bayes, SVM, xgboost)\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(train, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39004699-75c7-4de4-be35-6f45cd6247bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report on model Accuracy\n",
    "knn_pred = knn.predict(test)\n",
    "metrics.accuracy_score(target_test, knn_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
